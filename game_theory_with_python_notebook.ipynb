{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "colab": {
   "name": "game-theory-with-python-notebook.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m80rXVF8I5AN",
    "colab_type": "text"
   },
   "source": [
    "# Game Theory With Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_WtqfivI5AO",
    "colab_type": "text"
   },
   "source": [
    "### Welcome to the course. \n",
    "### Glad to have you onboard in this journey to explore two Game Theory packages in Python\n",
    "\n",
    "#### Nashpy & Axelrod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gKmBcHBI5AP",
    "colab_type": "text"
   },
   "source": [
    "#### 7 Tasks\n",
    "#### 1. Create games with Nashpy\n",
    "#### 2. Mixed strategies and Utilities\n",
    "#### 3. Nash Equilibrium\n",
    "#### 4. Games with multiple Nash Equilibria\n",
    "#### 5. Zero Sum Game\n",
    "#### 6. Create repeated game\n",
    "#### 7. Analyze Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQPnHp9SI5AQ",
    "colab_type": "text"
   },
   "source": [
    "## Two Player Games with Nashpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKYKZgVyI5AR",
    "colab_type": "text"
   },
   "source": [
    "## 1. Create 2 player games - Using Nashpy\n",
    "The Goal here is to learn how to create games based on payoff matrices!\n",
    "### Consider the following Prisoner's Dilemma matrix\n",
    "\n",
    "![picture](img/img1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vDUwerlDI5AS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import nashpy as nash\n",
    "import numpy as np"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pay off will be stored for each player in a numpy matrix and then passed to a `Game` object from the `nash` module"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "D-rB1BgYI5Aa",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Create the payoff matrix\n",
    "\n",
    "P1 = np.array([[8,1],[15,3]]) #row player\n",
    "P2 = np.array([[8,15],[1,3]]) # column player\n",
    "pdi = nash.Game(P1,P2)\n",
    "pdi\n"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Bi matrix game with payoff matrices:\n\nRow player:\n[[ 8  1]\n [15  3]]\n\nColumn player:\n[[ 8 15]\n [ 1  3]]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mapgZsumI5Ae",
    "colab_type": "text"
   },
   "source": [
    "### Exercise: Create a two player game, where,\n",
    "\n",
    "#### I. Name players as A and B\n",
    "#### II. Name the game as 'gm' and \n",
    "#### III. Use the follwing matrix\n",
    "\n",
    "![picture](./img/img2.PNG)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LBZatKa-I5Af",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "PA = np.array([[5,17],[14,12]])\n",
    "PB = np.array([[15,16],[2,8]])\n",
    "gm = nash.Game(PA,PB)\n",
    "gm"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Bi matrix game with payoff matrices:\n\nRow player:\n[[ 5 17]\n [14 12]]\n\nColumn player:\n[[15 16]\n [ 2  8]]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvPz8NuJI5Aj",
    "colab_type": "text"
   },
   "source": [
    "## 2. Mixed Strategy and Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-_cqcSQI5Ak",
    "colab_type": "text"
   },
   "source": [
    "### Pure Strategy: \n",
    "\n",
    "A complete definition of how a player will play a game, it yields optimum payoff to the player. \n",
    "\n",
    "### Mixed Strategy: \n",
    "\n",
    "Assigns a probability to each pure strategy. This allows for a player to randomly select a pure strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV3SS2IKI5Am",
    "colab_type": "text"
   },
   "source": [
    "### Calculating Utilities:\n",
    "\n",
    "![picture](img/img3.png)\n",
    "\n",
    "#### Consider the following Mixed Strategy\n",
    "\n",
    "σr=(.2,.8) and σc=(.6,.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now calculate the utilities for the mixed strategies by putting the coeficient into numpy array and scripting them from the game"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XPaaw8GXI5An",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Calculate Utilities\n",
    "\n",
    "sigma_r = np.array([0.2,.8])\n",
    "sigma_c = np.array([.6,.4])\n",
    "pdi = nash.Game(P1, P2)\n",
    "pdi[sigma_r, sigma_c]"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([9.2, 3.6])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "9.2"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ur(σr,σc)\n",
    "ur=0.2*0.6*8+0.2*0.4*1+0.8*0.6*15+0.8*0.4*3\n",
    "ur"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W6KZrnGxI5Au",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#uc(σr,σc)\n",
    "uc=0.2*0.6*8+0.2*0.4*15+0.8*0.6*1+0.8*0.4*3\n",
    "uc"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "3.6000000000000005"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y28VJqzfI5A2",
    "colab_type": "text"
   },
   "source": [
    "### Exercise: Calculate the utilities of the game 'gm' created in the previous exercise, using \n",
    "#### σr=(.3,.7) and σc=(.5,.5)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qf6LY92kI5A3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "sigma_A = np.array([0.3,.7])\n",
    "sigma_B = np.array([.5,.5])\n",
    "gm = nash.Game(PA, PB)\n",
    "gm[sigma_A, sigma_B]"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([12.4 ,  8.15])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF4K0KlOI5A7",
    "colab_type": "text"
   },
   "source": [
    "## 3. The Nash Equilibrium\n",
    "\n",
    "Strict and unique Nash Equilibrium\n",
    "\n",
    "![picture](img/img4.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H9mFNqgOI5A8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Find the Nash Equilibrium with Support Enumeration\n",
    "\n",
    "equilibria = pdi.support_enumeration()\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([0., 1.]))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faBuCYODI5A_",
    "colab_type": "text"
   },
   "source": [
    "#### Both solutions match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nFjsLoUI5BA",
    "colab_type": "text"
   },
   "source": [
    "### Exercise: Find out the Nash Equilibrium for gm"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-WDnIp6SI5BB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "for eq in gm.support_enumeration():\n",
    "    print(eq)"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1., 0.]), array([0., 1.]))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY2yrKJNI5BG",
    "colab_type": "text"
   },
   "source": [
    "## 4. Games with Multiple Nash Equilibria\n",
    "\n",
    "### Hawk - Dove Game\n",
    "\n",
    "![picture](img/img5.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aQg_1AIMI5BG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "P3 =  np.array([[3,1],[4,0]]) #P3 is p1 in image\n",
    "P4 =  np.array([[3,4],[1,0]])# P4 is the column player (p2 in image\n",
    "hd = nash.Game(P3,P4)\n",
    "hd"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Bi matrix game with payoff matrices:\n\nRow player:\n[[3 1]\n [4 0]]\n\nColumn player:\n[[3 4]\n [1 0]]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdUrrBQ9I5BK",
    "colab_type": "text"
   },
   "source": [
    "#### Nash Equilibria\n",
    "\n",
    "![picture](img/img6.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BiVKP_72I5BL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "equilibria = hd.support_enumeration()\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1., 0.]), array([0., 1.]))\n",
      "(array([0., 1.]), array([1., 0.]))\n",
      "(array([0.5, 0.5]), array([0.5, 0.5]))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xolws3tSI5BO",
    "colab_type": "text"
   },
   "source": [
    "Sol. (D,H)\n",
    "\n",
    "P3 : D = 1, H = 0\n",
    "\n",
    "P4 : D = 0, H = 1\n",
    "\n",
    "Sol. (H,D)\n",
    "\n",
    "P3 : D = 0, H = 1\n",
    "\n",
    "P4 : D = 1, H = 0\n",
    "\n",
    "Sol. (D,D) or (H,H)\n",
    "\n",
    "P3 : D = 0.5, H = 0.5\n",
    "\n",
    "P4 : D = 0.5, H = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVaY16XNI5BO",
    "colab_type": "text"
   },
   "source": [
    "### Exercise: Find out the number of NE for the following matrix\n",
    "#### Players: M and N\n",
    "#### Name of game mn\n",
    "\n",
    "\n",
    "![picture](img/img7.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4NW4qyI4I5BP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "PM=np.array([[1,1,3,2],[2,3,4,3],[5,1,1,4]])\n",
    "PN=np.array([[3,2,2,4],[1,4,2,0],[3,3,2,3]])\n",
    "g2=nash.Game(PM,PN)\n",
    "g2"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Bi matrix game with payoff matrices:\n\nRow player:\n[[1 1 3 2]\n [2 3 4 3]\n [5 1 1 4]]\n\nColumn player:\n[[3 2 2 4]\n [1 4 2 0]\n [3 3 2 3]]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dbR3SnMPI5BS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "for eq in g2.support_enumeration():\n",
    "    print(eq)"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1., 0.]), array([0., 1., 0., 0.]))\n",
      "(array([0., 0., 1.]), array([1., 0., 0., 0.]))\n",
      "(array([0., 0., 1.]), array([0., 0., 0., 1.]))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2_Z8uVlI5BW",
    "colab_type": "text"
   },
   "source": [
    "![picture](img/img8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NhqPum6I5BX",
    "colab_type": "text"
   },
   "source": [
    "## 5. Zero Sum Game\n",
    "\n",
    "Matching the pennies game\n",
    "\n",
    "![picture](img/5-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3w_YHAZTI5BX",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "P5 = np.array([[1,-1],[-1,1]])\n",
    "mp = nash.Game(P5)\n",
    "mp"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Zero sum game with payoff matrices:\n\nRow player:\n[[ 1 -1]\n [-1  1]]\n\nColumn player:\n[[-1  1]\n [ 1 -1]]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "U9bM_W8eI5Bg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "for eq in mp.support_enumeration():\n",
    "    print(eq)"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.5, 0.5]), array([0.5, 0.5]))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwgfpFL-I5Bk",
    "colab_type": "text"
   },
   "source": [
    "### Exercise: Find out the solution for the following zero sum game 'zs'\n",
    "#### Use payoff matrix - np.array([[5, -6.5], [-2.5, 7]]) \n",
    "#### For players Z1 and Z2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B9ypJKPZI5Bl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "PO = np.array([[5, -6.5], [-2.5, 7]])\n",
    "zs = nash.Game(PO)\n",
    "zs"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "Zero sum game with payoff matrices:\n\nRow player:\n[[ 5.  -6.5]\n [-2.5  7. ]]\n\nColumn player:\n[[-5.   6.5]\n [ 2.5 -7. ]]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9qPZdieaI5Bo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "for eq in zs.support_enumeration():\n",
    "    print (eq)"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.45238095, 0.54761905]), array([0.64285714, 0.35714286]))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVM0LDlfI5Br",
    "colab_type": "text"
   },
   "source": [
    "## Two Player-Repeated Games with Axelrod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJtMM67EI5Bs",
    "colab_type": "text"
   },
   "source": [
    "## 6. Create repeated game"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-qiWUNZ2I5Bs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#!pip install -U pyYAML     # Troubleshoot: Execute this line if Axelrod does not run and AttributeError: module 'yaml' has no attribute 'FullLoader' occurs\n",
    "\n",
    "import axelrod as axl"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xAlZskFMI5Bv",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Create matches\n",
    "\n",
    "players = (axl.Cooperator(),axl.Alternator())                  # using players of Cooperator and Alternator strategy\n",
    "match1 =   axl.Match(players, turns = 5)                          # play for 5 turns\n",
    "match1.play()"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[(C, C), (C, D), (C, C), (C, D), (C, C)]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "InpWBSpII5Bx",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "axl.all_strategies"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "[axelrod.strategies.memoryone.ALLCorALLD,\n axelrod.strategies.memorytwo.AON2,\n axelrod.strategies.apavlov.APavlov2006,\n axelrod.strategies.apavlov.APavlov2011,\n axelrod.strategies.adaptive.Adaptive,\n axelrod.strategies.titfortat.AdaptiveTitForTat,\n axelrod.strategies.adaptor.AdaptorBrief,\n axelrod.strategies.adaptor.AdaptorLong,\n axelrod.strategies.grudger.Aggravater,\n axelrod.strategies.titfortat.Alexei,\n axelrod.strategies.alternator.Alternator,\n axelrod.strategies.hunter.AlternatorHunter,\n axelrod.strategies.cycler.AntiCycler,\n axelrod.strategies.titfortat.AntiTitForTat,\n axelrod.strategies.appeaser.Appeaser,\n axelrod.strategies.qlearner.ArrogantQLearner,\n axelrod.strategies.averagecopier.AverageCopier,\n axelrod.strategies.backstabber.BackStabber,\n axelrod.strategies.better_and_better.BetterAndBetter,\n axelrod.strategies.titfortat.Bully,\n axelrod.strategies.bush_mosteller.BushMosteller,\n axelrod.strategies.calculator.Calculator,\n axelrod.strategies.grudger.Capri,\n axelrod.strategies.qlearner.CautiousQLearner,\n axelrod.strategies.prober.CollectiveStrategy,\n axelrod.strategies.titfortat.ContriteTitForTat,\n axelrod.strategies.cooperator.Cooperator,\n axelrod.strategies.hunter.CooperatorHunter,\n axelrod.strategies.hunter.CycleHunter,\n axelrod.strategies.cycler.CyclerCCCCCD,\n axelrod.strategies.cycler.CyclerCCCD,\n axelrod.strategies.cycler.CyclerCCCDCD,\n axelrod.strategies.cycler.CyclerCCD,\n axelrod.strategies.cycler.CyclerDC,\n axelrod.strategies.cycler.CyclerDDC,\n axelrod.strategies.dbs.DBS,\n axelrod.strategies.darwin.Darwin,\n axelrod.strategies.defector.Defector,\n axelrod.strategies.hunter.DefectorHunter,\n axelrod.strategies.memorytwo.DelayedAON1,\n axelrod.strategies.mutual.Desperate,\n axelrod.strategies.prober.Detective,\n axelrod.strategies.backstabber.DoubleCrosser,\n axelrod.strategies.resurrection.DoubleResurrection,\n axelrod.strategies.doubler.Doubler,\n axelrod.strategies.titfortat.DynamicTwoTitsForTat,\n axelrod.strategies.grudger.EasyGo,\n axelrod.strategies.titfortat.EugineNier,\n axelrod.strategies.hunter.EventualCycleHunter,\n axelrod.strategies.ann.EvolvedANN,\n axelrod.strategies.ann.EvolvedANN5,\n axelrod.strategies.ann.EvolvedANNNoise05,\n axelrod.strategies.finite_state_machines.EvolvedFSM16,\n axelrod.strategies.finite_state_machines.EvolvedFSM16Noise05,\n axelrod.strategies.finite_state_machines.EvolvedFSM4,\n axelrod.strategies.finite_state_machines.EvolvedFSM6,\n axelrod.strategies.hmm.EvolvedHMM5,\n axelrod.strategies.lookerup.EvolvedLookerUp1_1_1,\n axelrod.strategies.lookerup.EvolvedLookerUp2_2_2,\n axelrod.strategies.memoryone.FirmButFair,\n axelrod.strategies.axelrod_first.FirstByAnonymous,\n axelrod.strategies.axelrod_first.FirstByDavis,\n axelrod.strategies.axelrod_first.FirstByDowning,\n axelrod.strategies.axelrod_first.FirstByFeld,\n axelrod.strategies.axelrod_first.FirstByGraaskamp,\n axelrod.strategies.axelrod_first.FirstByGrofman,\n axelrod.strategies.axelrod_first.FirstByJoss,\n axelrod.strategies.axelrod_first.FirstByNydegger,\n axelrod.strategies.axelrod_first.FirstByShubik,\n axelrod.strategies.axelrod_first.FirstBySteinAndRapoport,\n axelrod.strategies.axelrod_first.FirstByTidemanAndChieruzzi,\n axelrod.strategies.axelrod_first.FirstByTullock,\n axelrod.strategies.oncebitten.FoolMeOnce,\n axelrod.strategies.oncebitten.ForgetfulFoolMeOnce,\n axelrod.strategies.grudger.ForgetfulGrudger,\n axelrod.strategies.forgiver.Forgiver,\n axelrod.strategies.forgiver.ForgivingTitForTat,\n axelrod.strategies.finite_state_machines.Fortress3,\n axelrod.strategies.finite_state_machines.Fortress4,\n axelrod.strategies.memoryone.GTFT,\n axelrod.strategies.grudger.GeneralSoftGrudger,\n axelrod.strategies.gobymajority.GoByMajority,\n axelrod.strategies.gobymajority.GoByMajority10,\n axelrod.strategies.gobymajority.GoByMajority20,\n axelrod.strategies.gobymajority.GoByMajority40,\n axelrod.strategies.gobymajority.GoByMajority5,\n axelrod.strategies.mathematicalconstants.Golden,\n axelrod.strategies.titfortat.Gradual,\n axelrod.strategies.gradualkiller.GradualKiller,\n axelrod.strategies.grudger.Grudger,\n axelrod.strategies.grudger.GrudgerAlternator,\n axelrod.strategies.grumpy.Grumpy,\n axelrod.strategies.handshake.Handshake,\n axelrod.strategies.gobymajority.HardGoByMajority,\n axelrod.strategies.gobymajority.HardGoByMajority10,\n axelrod.strategies.gobymajority.HardGoByMajority20,\n axelrod.strategies.gobymajority.HardGoByMajority40,\n axelrod.strategies.gobymajority.HardGoByMajority5,\n axelrod.strategies.prober.HardProber,\n axelrod.strategies.titfortat.HardTitFor2Tats,\n axelrod.strategies.titfortat.HardTitForTat,\n axelrod.strategies.qlearner.HesitantQLearner,\n axelrod.strategies.mutual.Hopeless,\n axelrod.strategies.inverse.Inverse,\n axelrod.strategies.punisher.InversePunisher,\n axelrod.strategies.worse_and_worse.KnowledgeableWorseAndWorse,\n axelrod.strategies.punisher.LevelPunisher,\n axelrod.strategies.retaliate.LimitedRetaliate,\n axelrod.strategies.retaliate.LimitedRetaliate2,\n axelrod.strategies.retaliate.LimitedRetaliate3,\n axelrod.strategies.memorytwo.MEM2,\n axelrod.strategies.hunter.MathConstantHunter,\n axelrod.strategies.titfortat.Michaelos,\n axelrod.strategies.titfortat.NTitsForMTats,\n axelrod.strategies.prober.NaiveProber,\n axelrod.strategies.negation.Negation,\n axelrod.strategies.averagecopier.NiceAverageCopier,\n axelrod.strategies.titfortat.OmegaTFT,\n axelrod.strategies.oncebitten.OnceBitten,\n axelrod.strategies.grudger.OppositeGrudger,\n axelrod.strategies.titfortat.OriginalGradual,\n axelrod.strategies.gambler.PSOGambler1_1_1,\n axelrod.strategies.gambler.PSOGambler2_2_2,\n axelrod.strategies.gambler.PSOGambler2_2_2_Noise05,\n axelrod.strategies.gambler.PSOGamblerMem1,\n axelrod.strategies.mathematicalconstants.Pi,\n axelrod.strategies.finite_state_machines.Predator,\n axelrod.strategies.prober.Prober,\n axelrod.strategies.prober.Prober2,\n axelrod.strategies.prober.Prober3,\n axelrod.strategies.prober.Prober4,\n axelrod.strategies.finite_state_machines.Pun1,\n axelrod.strategies.punisher.Punisher,\n axelrod.strategies.finite_state_machines.Raider,\n axelrod.strategies.rand.Random,\n axelrod.strategies.hunter.RandomHunter,\n axelrod.strategies.titfortat.RandomTitForTat,\n axelrod.strategies.prober.RemorsefulProber,\n axelrod.strategies.resurrection.Resurrection,\n axelrod.strategies.retaliate.Retaliate,\n axelrod.strategies.retaliate.Retaliate2,\n axelrod.strategies.retaliate.Retaliate3,\n axelrod.strategies.revised_downing.RevisedDowning,\n axelrod.strategies.finite_state_machines.Ripoff,\n axelrod.strategies.qlearner.RiskyQLearner,\n axelrod.strategies.axelrod_second.SecondByAppold,\n axelrod.strategies.axelrod_second.SecondByBlack,\n axelrod.strategies.axelrod_second.SecondByBorufsen,\n axelrod.strategies.axelrod_second.SecondByCave,\n axelrod.strategies.axelrod_second.SecondByChampion,\n axelrod.strategies.axelrod_second.SecondByColbert,\n axelrod.strategies.axelrod_second.SecondByEatherley,\n axelrod.strategies.axelrod_second.SecondByGetzler,\n axelrod.strategies.axelrod_second.SecondByGladstein,\n axelrod.strategies.axelrod_second.SecondByGraaskampKatzen,\n axelrod.strategies.axelrod_second.SecondByGrofman,\n axelrod.strategies.axelrod_second.SecondByHarrington,\n axelrod.strategies.axelrod_second.SecondByKluepfel,\n axelrod.strategies.axelrod_second.SecondByLeyvraz,\n axelrod.strategies.axelrod_second.SecondByMikkelson,\n axelrod.strategies.axelrod_second.SecondByRichardHufford,\n axelrod.strategies.axelrod_second.SecondByRowsam,\n axelrod.strategies.axelrod_second.SecondByTester,\n axelrod.strategies.axelrod_second.SecondByTidemanAndChieruzzi,\n axelrod.strategies.axelrod_second.SecondByTranquilizer,\n axelrod.strategies.axelrod_second.SecondByWeiner,\n axelrod.strategies.axelrod_second.SecondByWhite,\n axelrod.strategies.axelrod_second.SecondByWmAdams,\n axelrod.strategies.axelrod_second.SecondByYamachi,\n axelrod.strategies.selfsteem.SelfSteem,\n axelrod.strategies.shortmem.ShortMem,\n axelrod.strategies.titfortat.SlowTitForTwoTats2,\n axelrod.strategies.titfortat.SneakyTitForTat,\n axelrod.strategies.grudger.SoftGrudger,\n axelrod.strategies.memoryone.SoftJoss,\n axelrod.strategies.finite_state_machines.SolutionB1,\n axelrod.strategies.finite_state_machines.SolutionB5,\n axelrod.strategies.titfortat.SpitefulTitForTat,\n axelrod.strategies.grudger.SpitefulCC,\n axelrod.strategies.stalker.Stalker,\n axelrod.strategies.memoryone.StochasticCooperator,\n axelrod.strategies.memoryone.StochasticWSLS,\n axelrod.strategies.titfortat.SuspiciousTitForTat,\n axelrod.strategies.finite_state_machines.TF1,\n axelrod.strategies.finite_state_machines.TF2,\n axelrod.strategies.finite_state_machines.TF3,\n axelrod.strategies.sequence_player.ThueMorse,\n axelrod.strategies.sequence_player.ThueMorseInverse,\n axelrod.strategies.finite_state_machines.Thumper,\n axelrod.strategies.titfortat.TitFor2Tats,\n axelrod.strategies.titfortat.TitForTat,\n axelrod.strategies.cooperator.TrickyCooperator,\n axelrod.strategies.defector.TrickyDefector,\n axelrod.strategies.punisher.TrickyLevelPunisher,\n axelrod.strategies.titfortat.TwoTitsForTat,\n axelrod.strategies.finite_state_machines.UsuallyCooperates,\n axelrod.strategies.finite_state_machines.UsuallyDefects,\n axelrod.strategies.verybad.VeryBad,\n axelrod.strategies.mutual.Willing,\n axelrod.strategies.memoryone.WinShiftLoseStay,\n axelrod.strategies.memoryone.WinStayLoseShift,\n axelrod.strategies.lookerup.Winner12,\n axelrod.strategies.lookerup.Winner21,\n axelrod.strategies.worse_and_worse.WorseAndWorse,\n axelrod.strategies.worse_and_worse.WorseAndWorse2,\n axelrod.strategies.worse_and_worse.WorseAndWorse3,\n axelrod.strategies.zero_determinant.ZDExtort2,\n axelrod.strategies.zero_determinant.ZDExtort2v2,\n axelrod.strategies.zero_determinant.ZDExtort3,\n axelrod.strategies.zero_determinant.ZDExtort4,\n axelrod.strategies.zero_determinant.ZDExtortion,\n axelrod.strategies.zero_determinant.ZDGTFT2,\n axelrod.strategies.zero_determinant.ZDGen2,\n axelrod.strategies.gambler.ZDMem2,\n axelrod.strategies.zero_determinant.ZDMischief,\n axelrod.strategies.zero_determinant.ZDSet2,\n axelrod.strategies.mathematicalconstants.e,\n axelrod.strategies.meta.MemoryDecay,\n axelrod.strategies.meta.MetaHunter,\n axelrod.strategies.meta.MetaHunterAggressive,\n axelrod.strategies.meta.MetaMajority,\n axelrod.strategies.meta.MetaMajorityMemoryOne,\n axelrod.strategies.meta.MetaMajorityFiniteMemory,\n axelrod.strategies.meta.MetaMajorityLongMemory,\n axelrod.strategies.meta.MetaMinority,\n axelrod.strategies.meta.MetaMixer,\n axelrod.strategies.meta.MetaWinner,\n axelrod.strategies.meta.MetaWinnerDeterministic,\n axelrod.strategies.meta.MetaWinnerEnsemble,\n axelrod.strategies.meta.MetaWinnerMemoryOne,\n axelrod.strategies.meta.MetaWinnerFiniteMemory,\n axelrod.strategies.meta.MetaWinnerLongMemory,\n axelrod.strategies.meta.MetaWinnerStochastic,\n axelrod.strategies.meta.NMWEDeterministic,\n axelrod.strategies.meta.NMWEFiniteMemory,\n axelrod.strategies.meta.NMWELongMemory,\n axelrod.strategies.meta.NMWEMemoryOne,\n axelrod.strategies.meta.NMWEStochastic,\n axelrod.strategies.meta.NiceMetaWinner,\n axelrod.strategies.meta.NiceMetaWinnerEnsemble]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwEQbFjbI5B2",
    "colab_type": "text"
   },
   "source": [
    "### Exercise: Create a repeated game with 2 players having:\n",
    "#### I. TitForTat and Random Strategy \n",
    "#### II. Name it as match2\n",
    "#### III. Run it for 15 turns"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M8tlSW99I5B3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "players2=(axl.TitForTat(),axl.Random())\n",
    "match2= axl.Match(players2,turns=15)\n",
    "match2.play()"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[(C, C),\n (C, D),\n (D, C),\n (C, C),\n (C, C),\n (C, D),\n (D, D),\n (D, D),\n (D, D),\n (D, D),\n (D, D),\n (D, C),\n (C, D),\n (D, D),\n (D, C)]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hZOv2xQI5B_",
    "colab_type": "text"
   },
   "source": [
    "## 7. Analyze Match"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eD9qeCgEI5B_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Payoffs\n",
    "\n",
    "match1.game       #Analyze the match\n",
    "\n",
    "#These payoffs are commonly referred to as:\n",
    "\n",
    "#R: the Reward payoff (default value in the library: 3) C-C\n",
    "#P: the Punishment payoff (default value in the library: 1) D-D\n",
    "#S: the Loss payoff (default value in the library: 0) C-D\n",
    "#T: the Temptation payoff (default value in the library: 5) D-C"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "Axelrod game: (R,P,S,T) = (3, 1, 0, 5)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xs7rQEyZI5CC",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Scores of a match\n",
    "\n",
    "match1.scores()     #Retrieve match scores"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "[(3, 3), (0, 5), (3, 3), (0, 5), (3, 3)]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zCkP68lJI5CF",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# The result of the match can also be viewed as sparklines where cooperation is shown as a solid block and defection as a space. (in pycharm dark theme blocks are white and space are dark)\n",
    "\n",
    "print(match1.sparklines())  # Get output using sparklines"
   ],
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█████\n",
      "█ █ █\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkbk8a-NI5CH",
    "colab_type": "text"
   },
   "source": [
    "### Exercise: Analyze match2. \n",
    "#### Find the score and create the sparklines"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "snBJkfDJI5CI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "match2.scores()"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "[(3, 3),\n (0, 5),\n (5, 0),\n (3, 3),\n (3, 3),\n (0, 5),\n (1, 1),\n (1, 1),\n (1, 1),\n (1, 1),\n (1, 1),\n (5, 0),\n (0, 5),\n (1, 1),\n (5, 0)]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0665Gwk4I5CL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(match2.sparklines())"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "██ ███      █  \n",
      "█ ███      █  █\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9h2o5YmI5CP",
    "colab_type": "text"
   },
   "source": [
    "#### References:\n",
    "\n",
    "Package Documentations\n",
    "\n",
    "https://nashpy.readthedocs.io/en/stable/index.html#\n",
    "\n",
    "https://axelrod.readthedocs.io/en/stable/#"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## quizz coding\n",
    "### Q1\n",
    "![image](img/A1Q1.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "Bi matrix game with payoff matrices:\n\nRow player:\n[[100  35]\n [175  50]]\n\nColumn player:\n[[100 175]\n [ 35  50]]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=np.array([[100,35],[175,50]])\n",
    "B=np.array([[100,175],[35,50]])\n",
    "game_q1=nash.Game(A,B)\n",
    "game_q1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q2\n",
    "![](img/A1Q2.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([0., 1.]))\n"
     ]
    }
   ],
   "source": [
    "for eq in game_q1.support_enumeration():\n",
    "    print(eq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q3\n",
    "![](img/A1Q3.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([109.7,  67.7])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_A=np.array([.3,.7])\n",
    "sigma_B=np.array([.6,.4])\n",
    "game_q1[sigma_A,sigma_B]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q4\n",
    "![](img/A1Q4.png)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option1\n",
      "---------\n",
      "█ █ █ █ █ █ \n",
      "██ █ █ █ █ █\n",
      "===============\n",
      "option2\n",
      "---------\n",
      "██ █ █ █ █ █\n",
      "█ █ █ █ █ █ \n",
      "===============\n",
      "option3\n",
      "---------\n",
      "████████████\n",
      "            \n",
      "===============\n",
      "option4\n",
      "---------\n",
      "            \n",
      "            \n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "print(\"option1\")\n",
    "print(9*'-')\n",
    "players = (axl.Alternator(),axl.TitForTat())\n",
    "match= axl.Match(players,turns=12)\n",
    "match.play()\n",
    "print(match.sparklines())\n",
    "print(15*'=')\n",
    "\n",
    "\n",
    "print(\"option2\")\n",
    "print(9*'-')\n",
    "players = (axl.TitForTat(),axl.Alternator())\n",
    "match= axl.Match(players,turns=12)\n",
    "match.play()\n",
    "print(match.sparklines())\n",
    "print(15*'=')\n",
    "\n",
    "\n",
    "print(\"option3\")\n",
    "print(9*'-')\n",
    "players = (axl.Cooperator(),axl.Defector())\n",
    "match= axl.Match(players,turns=12)\n",
    "match.play()\n",
    "print(match.sparklines())\n",
    "print(15*'=')\n",
    "\n",
    "\n",
    "print(\"option4\")\n",
    "print(9*'-')\n",
    "players = (axl.Defector(),axl.Defector())\n",
    "match= axl.Match(players,turns=12)\n",
    "match.play()\n",
    "print(match.sparklines())\n",
    "print(15*'=')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q5\n",
    "![](img/A1Q5.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}